<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="www.elusivecode.net/feed.xml" rel="self" type="application/atom+xml" /><link href="www.elusivecode.net/" rel="alternate" type="text/html" /><updated>2019-01-29T18:03:54-05:00</updated><id>www.elusivecode.net/feed.xml</id><title type="html">Matt Parker</title><subtitle>Ramblings of a SysAdmin.</subtitle><author><name>Matt Parker</name></author><entry><title type="html">Speeding up System Center OS Deployment</title><link href="www.elusivecode.net/networking/SCCM-OSD-Speed/" rel="alternate" type="text/html" title="Speeding up System Center OS Deployment" /><published>2019-01-29T09:36:51-05:00</published><updated>2019-01-29T09:36:51-05:00</updated><id>www.elusivecode.net/networking/SCCM-OSD-Speed</id><content type="html" xml:base="www.elusivecode.net/networking/SCCM-OSD-Speed/">&lt;p&gt;    Some of the goals of the exercise was to add some automation to a task sequence and also speed up the results so that to not hinder the technicians that do the deployments.&lt;/p&gt;

&lt;p&gt;    We wanted to add bit-locker encryption to the task sequence, with full disk encryption to add security to reused disks for re-images. SCCM support for FVE (Full Volume encryption) was just added in 1806. Through testing it appears that the implementation is buggy at best, anytime we did a sequence with FVE turned on, when tested on machines with TPM 1.2 it would fail. Machines that were running TPM 2.0 would sometimes work fine and sometimes would not. Through testing we concluded that doing the used space encryption as before and add a step of “Manage-bde -w C:” would give us the same end benefit with one caveat, manage-bde -status will remain saying used space encryption. This is despite that a full disk wipe does occur.&lt;/p&gt;

&lt;p&gt;    We also wanted to implement our Bit9 Carbon black agent in to the sequence. Carbon black goes through an initialization process where it catalogs all files on the system. This in a combination of FVE and antivirus caused major slow down to the image. Testing was done on a slower in production desktop, an I7-4790, 8 gigs of ram, and a 7200 RPM platter drive.&lt;/p&gt;

&lt;p&gt;    We tested through multiple orders to try to minimize the performance hit, and to give the technicians the best experience as relates to time, and after deployment slowness. Through testing, We noticed Bit9 did its initialization as a foreground type task, taking all free disk cycles without sharing. Free space wipe did seem to background its process a lot, it did not cause a major slowdown, so the techs could continue user setup while it was processing if needed.&lt;/p&gt;

&lt;p&gt;Below is a chart of timings.&lt;/p&gt;

&lt;table class=&quot;mbtablestyle&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Options&lt;/th&gt;
      &lt;th&gt;Time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;No wipe no bit9&lt;/td&gt;
      &lt;td&gt;45 Minutes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Wipe, No Bit9&lt;/td&gt;
      &lt;td&gt;1:45&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;No Wipe with Bit9&lt;/td&gt;
      &lt;td&gt;1:07&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Wipe, Bit9&lt;/td&gt;
      &lt;td&gt;2:26&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Bit9, Auto wait, wipe at end&lt;/td&gt;
      &lt;td&gt;1:00 to usable&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;    The Auto-wait was a replacement, the original idea was to time bit9 on both flash and hdd and set up an if type statement to do approximate timings, but that would case some inconsistencies on the wait, and despite tuning we wouldn’t ever be able to get it “just right”. I dug into Bit9 to see if there was some way to call a status from the machine itself so it would be available during the task sequence. There was a CLI tool that is provided that gave insight, so I wrote a Powershell script that would call it in a loop and continue until complete.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-Powershell&quot;&gt;    &amp;lt;#
.SYNOPSIS
A script to run immediately after deploying the Bit9 Carbon Black Protect Agent during OS deployment 
and wait for it to complete the initial cache before proceeding.
#&amp;gt;


Write-host (get-date)
$start = (get-date)
#Wait to make sure Bit9 Started
start-sleep -seconds 120

do {
    #Check for timeout
    $tolate = ((get-date) -gt ($start.AddMinutes(40)))
    #break if time is hit
    if ($tolate){Break}
    Write-Host &quot;Sleeping 30 Seconds&quot;
    Start-sleep -seconds 30
    #get status
    $status =  &amp;amp; 'C:\Program Files (x86)\Bit9\Parity Agent\DasCLI.exe' status
    #match if completed
    $Check = $status -match &quot;Initialized&quot;

} While ($null -like $check)

Write-host (get-date)
Write-host &quot;Finished&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;https://github.com/MattLParker/Powershell/blob/master/Status-bit9.ps1&lt;/p&gt;

&lt;p&gt;    As you can see we were able to save some considerable time by adjusting the order in which things are completed.&lt;/p&gt;</content><author><name>Matt Parker</name></author><summary type="html">    Some of the goals of the exercise was to add some automation to a task sequence and also speed up the results so that to not hinder the technicians that do the deployments.</summary></entry><entry><title type="html">DNS Forwarders</title><link href="www.elusivecode.net/networking/DNS-Forwarders/" rel="alternate" type="text/html" title="DNS Forwarders" /><published>2019-01-29T09:36:51-05:00</published><updated>2019-01-29T09:36:51-05:00</updated><id>www.elusivecode.net/networking/DNS-Forwarders</id><content type="html" xml:base="www.elusivecode.net/networking/DNS-Forwarders/">&lt;p&gt;    When setting up or maintaining multiple AD domains, due to legacy environments. It is not wise to point the DNS servers of the new domain to the old servers.&lt;/p&gt;

&lt;p&gt;    I recently discovered this done on a 1700 user AD environment. There was a constant slow to resolve DNS when browsing the web. The internet connectivity on location was a 500/500 fiber with modern firewalls. Needless to say it was not fault of the internet connection. While troubleshooting the slowness issue the error that was consistent was NXdomain. I discovered that some one previous has set the forwarders to the old AD environment’s domain controllers, of which only one was still operational the rest had been shut down as the domain is being decommissioned. The previous had actually set up the new network to poll the old network which in turn polled the internet. After making the approved changes to point outbound instead of old, At least it was discovered why it was done, intermittent connectivity to servers in the old forest. Which was a result of only one of the new AD/DNS servers having the secondary zone and no conditional forwarders in place. Why put a bandage on a broken leg gets me but trust nothing, especially DNS. So remember, It is always DNS.&lt;/p&gt;</content><author><name>Matt Parker</name></author><summary type="html">    When setting up or maintaining multiple AD domains, due to legacy environments. It is not wise to point the DNS servers of the new domain to the old servers.</summary></entry><entry><title type="html">Internal Nat Design</title><link href="www.elusivecode.net/networking/Internal-Nat-Design/" rel="alternate" type="text/html" title="Internal Nat Design" /><published>2019-01-29T09:36:51-05:00</published><updated>2019-01-29T09:36:51-05:00</updated><id>www.elusivecode.net/networking/Internal-Nat-Design</id><content type="html" xml:base="www.elusivecode.net/networking/Internal-Nat-Design/">&lt;p&gt;    Time has come where a service that we run is being moved to a remote (read not ours) datacenter. We do not know all the internal workings of it as it is a Mainframe Z9, in which we no longer have any programmers on staff. We are having the services brought up on some one else’s cloud due to not being able to properly provide disaster recovery.&lt;/p&gt;

&lt;p&gt;    One of the many challenges that has come up during this adventure is that since we do not have any programmers, and the last time we did was when all of the networking staff thought static routes and /20’s were the best thing since sliced bread. One of the things that we do know is all of the jobs that the mainframe uses back and forth is hard-coded IP addresses for all of the external to mainframe imports and exports. Since the mainframe is on one of the last remaining /20’s in which there are also several servers and clients on this subnet, we had to implement a way that we can use it’s current IP, with the cloud connection.&lt;/p&gt;

&lt;p&gt;    First thing that was established is having an IPsec tunnel built to our cloud mainframe. That I will not bore with the details of since it is a standard tunnel ASA to ASA. Testing by our operators have been going with very few problems to speak of relatively. Next the thought of how to reprogram a ton of Mainframe jobs, or how to reuse the same IP address for the cloud mainframe.&lt;/p&gt;

&lt;p&gt;    Some thoughts of being able to NAT the address came up, but how, on a network that is currently in place as a /20.&lt;/p&gt;

&lt;p&gt;    For the sake of public we are going to use 1.1.1.0/20 as the network in question, and 1.1.1.2 as the mainframe internal, and 11.11.11.11 as the cloud mainframe.
To start, we placed on our Layer 3 switch that is closest a static route of 1.1.1.2/32 pointing it to the ASA. We run EIGRP and have static redistribute enabled on the LAN EIGRP.&lt;/p&gt;

&lt;p&gt;    Next since we have multiple WAN routes a static route was placed in the ASA pointing 1.1.1.2/32 to the correct WAN that the tunnel was built on. Next we did a NAT for 1.1.1.2 &amp;lt;&amp;gt;-&amp;lt;&amp;gt;11.11.11.11 and we seem to have a working NAT. Pings to 1.1.1.2 work fine from most of the network, but alas, it does not work from the 1.1.1.0/20 network. Which we assumed would not work as it would never make it to be routed, as it is a layer two address. Since the Layer3 in this case is a NX-OS device, I was able to set on the interface vlan, IP Proxy-arp. A command which the switch will relay the learned IP-Mac combinations from its own arp tables.&lt;/p&gt;</content><author><name>Matt Parker</name></author><summary type="html">    Time has come where a service that we run is being moved to a remote (read not ours) datacenter. We do not know all the internal workings of it as it is a Mainframe Z9, in which we no longer have any programmers on staff. We are having the services brought up on some one else’s cloud due to not being able to properly provide disaster recovery.</summary></entry><entry><title type="html">Skype for Business Desktop sharing disconnect.</title><link href="www.elusivecode.net/networking/Skype-Disconnect/" rel="alternate" type="text/html" title="Skype for Business Desktop sharing disconnect." /><published>2019-01-29T09:36:51-05:00</published><updated>2019-01-29T09:36:51-05:00</updated><id>www.elusivecode.net/networking/Skype-Disconnect</id><content type="html" xml:base="www.elusivecode.net/networking/Skype-Disconnect/">&lt;p&gt;    During testing of using Skype for business for Audio/Video conferencing all was going well, until enabling desktop sharing. When ever anyone in the group (all on LAN to each other) we would start a storm of disconnects from Skype.&lt;/p&gt;

&lt;p&gt;    While troubleshooting the problem, it was noticed that the person who initiated the desktop sharing would get a very brief, about 2-3 second drop from the internet completely. Through initiating a packet capture “Capture asp type asp-drop” we noticed that the client ip was getting shunned. It appears that “threat-detection scanning-threat”  was actually quick shunning the IP based on the UDP packet flood that was generated from Skype. A quick work around was to do a  “scanning-threat shun except ip-address 20.20.20.20 255.255.255.255” was a quick work around to the problem.&lt;/p&gt;</content><author><name>Matt Parker</name></author><summary type="html">    During testing of using Skype for business for Audio/Video conferencing all was going well, until enabling desktop sharing. When ever anyone in the group (all on LAN to each other) we would start a storm of disconnects from Skype.</summary></entry></feed>